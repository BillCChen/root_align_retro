accum_count: '1'
accum_steps:
- 0
adagrad_accumulator_init: 0
adam_beta1: '0.9'
adam_beta2: '0.998'
alignment_heads: 0
alignment_layer: -3
apex_opt_level: O1
attention_dropout: '0.3'
average_decay: 0
average_every: 1
batch_size: '128'
batch_type: sents
bidir_edges: true
bridge_extra_node: true
bucket_size: 2048
cnn_kernel_width: 3
config: pretrain_finetune/finetune/PtoTMPtoR/TMPtoR-50K-aug20-config.yml
data: '{''corpus_1'': {''path_src'': ''/root/reaction_data/pretrain_aug/USPTO_50K_PtoTMPtoR_aug20/train/tmp_product.txt'',
  ''path_tgt'': ''/root/reaction_data/pretrain_aug/USPTO_50K_PtoTMPtoR_aug20/train/tmp_reactant.txt''},
  ''valid'': {''path_src'': ''/root/reaction_data/pretrain_aug/USPTO_50K_PtoTMPtoR_aug20/val/tmp_product.txt'',
  ''path_tgt'': ''/root/reaction_data/pretrain_aug/USPTO_50K_PtoTMPtoR_aug20/val/tmp_reactant.txt''}}'
data_type: text
dec_layers: 2
dec_rnn_size: 500
decay_method: noam
decay_steps: 10000
decoder_type: transformer
dropout: '0.3'
dropout_steps:
- 0
early_stopping: 0
enc_layers: 2
enc_rnn_size: 500
encoder_type: transformer
epochs: 0
exp: ''
exp_host: ''
feat_merge: concat
feat_vec_exponent: 0.7
feat_vec_size: -1
generator_function: softmax
global_attention: general
global_attention_function: softmax
gpu_backend: nccl
gpu_ranks:
- 0
- 1
gpu_verbose_level: 0
gpuid: []
heads: '8'
input_feed: 1
insert_ratio: 0.0
keep_checkpoint: '40'
label_smoothing: '0.3'
lambda_align: 0.0
lambda_coverage: 0.0
layers: '6'
learning_rate: '1.0'
learning_rate_decay: 0.5
log_file: logs/TMPtoR_fromUSPTO50K_P2R-finetune_lbl_smt1.log
log_file_level: '0'
loss_scale: 0
mask_length: subword
mask_ratio: 0.0
master_ip: localhost
master_port: 10000
max_generator_batches: '0'
max_grad_norm: '0.0'
max_relative_positions: 0
model_dtype: fp32
model_task: seq2seq
model_type: text
n_edge_types: 2
n_node: 2
n_sample: '0'
n_steps: 2
normalization: sents
optim: adam
overwrite: 'False'
param_init: '0.0'
param_init_glorot: 'true'
permute_sent_ratio: 0.0
poisson_lambda: 3.0
pool_factor: 8192
pos_ffn_activation_fn: relu
position_encoding: 'true'
queue_size: 40
random_ratio: 0.0
replace_length: -1
report_every: '1000'
reset_optim: all
reversible_tokenization: joiner
rnn_size: '256'
rnn_type: LSTM
rotate_ratio: 0.0
save_checkpoint_steps: '10000'
save_config: 'True'
save_config_file: models/TMPtoR_fromUSPTO50K_P2R_aug20_smt3/finetune_config.yml
save_data: /root/reaction_data/pretrain_aug/USPTO_50K_PtoR_aug20/example
save_model: models/TMPtoR_fromUSPTO50K_P2R_aug20_smt3/finetune_model.product-template
seed: '3435'
self_attn_type: scaled-dot
share_vocab: 'true'
skip_empty_level: warning
src_ggnn_size: 0
src_onmttok_kwargs: '{''mode'': ''none''}'
src_seq_length: '500'
src_subword_alpha: 0
src_subword_nbest: 1
src_subword_type: none
src_subword_vocab: ''
src_vocab: /root/reaction_data/pretrain_aug/USPTO_50K_PtoR_aug20/example.vocab.src
src_vocab_size: 50000
src_vocab_threshold: 0
src_word_vec_size: 500
src_words_min_frequency: 0
start_decay_steps: 50000
state_dim: 512
switchout_temperature: 1.0
tensorboard: 'True'
tensorboard_log_dir: tensorboard/TMPtoR_fromUSPTO50K_P2R-finetune
tgt_onmttok_kwargs: '{''mode'': ''none''}'
tgt_seq_length: '500'
tgt_subword_alpha: 0
tgt_subword_nbest: 1
tgt_subword_type: none
tgt_subword_vocab: ''
tgt_vocab: /root/reaction_data/pretrain_aug/USPTO_50K_PtoR_aug20/example.vocab.src
tgt_vocab_size: 50000
tgt_vocab_threshold: 0
tgt_word_vec_size: 500
tgt_words_min_frequency: 0
tokendrop_temperature: 1.0
tokenmask_temperature: 1.0
train_from: models/PtoR/USPTO_50K_PtoR_lbl_smt_0.3.pt
train_steps: '400000'
transformer_ff: '2048'
transforms: []
truncated_decoder: 0
valid_batch_size: '128'
valid_steps: '50000'
vocab_size_multiple: 1
warmup_steps: '8000'
word_vec_size: '256'
world_size: '2'
